{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7buI8XYCHE8OsS74mzl6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmmanuelUCSP/Grafica-Final/blob/main/Implementacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJs-sPMCYPMf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "video_dir = '/content/drive/MyDrive/AQA_videos'\n",
        "files = os.listdir(video_dir)\n",
        "print(\"Archivos encontrados:\", files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, ReLU, AveragePooling3D, Concatenate\n",
        "from tensorflow.keras.layers import GlobalAveragePooling3D, Flatten, Dense\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "id": "d_nb6977YQYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conv3D-AQA***"
      ],
      "metadata": {
        "id": "YYgRxyCQYWyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, ReLU, AveragePooling3D, Concatenate\n",
        "from tensorflow.keras.layers import GlobalAveragePooling3D, Dense\n",
        "\n",
        "def build_conv3d_aqa(input_shape=(16, 112, 112, 3)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Rama 1\n",
        "    x1 = Conv3D(32, kernel_size=(3, 3, 3), padding='same')(inputs)\n",
        "    x1 = ReLU()(x1)\n",
        "\n",
        "    # Rama 2\n",
        "    x2 = Conv3D(32, kernel_size=(6, 3, 3), padding='same')(inputs)\n",
        "    x2 = ReLU()(x2)\n",
        "\n",
        "    # Rama 3 + Average Pooling (sin reducir dimensiones)\n",
        "    x3 = Conv3D(32, kernel_size=(3, 3, 3), padding='same')(inputs)\n",
        "    x3 = ReLU()(x3)\n",
        "    x3 = AveragePooling3D(pool_size=(1, 1, 1), padding='same')(x3)\n",
        "\n",
        "    # Concatenación de ramas\n",
        "    x = Concatenate()([x1, x2, x3])\n",
        "\n",
        "    # Bloques intermedios\n",
        "    x = Conv3D(64, kernel_size=(4, 3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv3D(64, kernel_size=(6, 3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    x = Conv3D(64, kernel_size=(1, 1, 1), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Fully connected\n",
        "    x = GlobalAveragePooling3D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "\n",
        "    # Salida: score único\n",
        "    outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zl4WjgXEYZgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Preprocesamiento***"
      ],
      "metadata": {
        "id": "kI3T0DXXY-U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "video_dir = '/content/drive/MyDrive/AQA_videos'\n",
        "video_files = []\n",
        "for root, _, files in os.walk(video_dir):\n",
        "    for f in files:\n",
        "        if f.endswith('.avi'):\n",
        "            full_path = os.path.join(root, f)\n",
        "            video_files.append(full_path)\n",
        "\n",
        "\n",
        "score_dict = {}\n",
        "for video_path in video_files:\n",
        "    # video_path: /content/drive/MyDrive/AQA_videos/diving/001.avi\n",
        "    relative_path = os.path.relpath(video_path, video_dir)  # diving/001.avi\n",
        "    score = round(random.uniform(2.0, 5.0), 2)\n",
        "    score_dict[relative_path] = score\n",
        "\n",
        "print(score_dict)"
      ],
      "metadata": {
        "id": "Wlr3JBHCZQu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_video_tensor(video_path, num_frames=16, size=(112, 112)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if total_frames < num_frames:\n",
        "        print(f\"⚠️ Video con pocos frames: {video_path} ({total_frames} frames)\")\n",
        "        return None\n",
        "\n",
        "    selected_idxs = np.linspace(0, total_frames - 1, num_frames).astype(int)\n",
        "    frames = []\n",
        "    frame_idx = 0\n",
        "    selected_pos = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx == selected_idxs[selected_pos]:\n",
        "            frame = cv2.resize(frame, size)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = frame / 255.0  # Normalización\n",
        "            frames.append(frame)\n",
        "            selected_pos += 1\n",
        "\n",
        "            if selected_pos == len(selected_idxs):\n",
        "                break\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(frames) != num_frames:\n",
        "        print(f\"❌ No se lograron extraer 16 frames de: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    return np.array(frames)\n"
      ],
      "metadata": {
        "id": "aCVoHrrFZSqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Compilar modelo***"
      ],
      "metadata": {
        "id": "JWAdrLqTZijR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_conv3d_aqa()\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "PIU4F6OsZkSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Train***"
      ],
      "metadata": {
        "id": "hqUNbZXnZn53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for relative_path, score in score_dict.items():\n",
        "    full_path = os.path.join(video_dir, relative_path)\n",
        "    tensor = load_video_tensor(full_path)\n",
        "\n",
        "    if tensor is not None and tensor.shape == (16, 112, 112, 3):\n",
        "        X.append(tensor)\n",
        "        y.append(score)\n",
        "    else:\n",
        "        print(f\"❌ Video descartado: {relative_path}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "2fjgb_MLaT--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce11a46d-6602-45dc-8da7-749576566e4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1189, 16, 112, 112, 3)\n",
            "y shape: (1189, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(X, y, epochs=20, batch_size=2, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "HvqOFh_PdHzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('/content/conv3d_aqa_model.h5')\n"
      ],
      "metadata": {
        "id": "YmDd4NdIb6DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Pruebas***"
      ],
      "metadata": {
        "id": "DE-Tez-rcXsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "model1 = load_model('/content/conv3d_aqa_model.h5', custom_objects={'mse': MeanSquaredError()})"
      ],
      "metadata": {
        "id": "fnc6jXKdcZoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo\n",
        "test_video_path = \"/content/drive/MyDrive/AQA_videos/gym_vault/001.avi\"\n",
        "\n",
        "test_tensor = load_video_tensor(test_video_path)\n",
        "\n",
        "if test_tensor is None:\n",
        "    print(\"❌ Error cargando el video.\")\n",
        "else:\n",
        "    # Asegura la forma (1, 16, 112, 112, 3)\n",
        "    test_tensor = np.expand_dims(test_tensor, axis=0)\n",
        "\n",
        "    # Predecir\n",
        "    prediction = model.predict(test_tensor)\n",
        "    print(f\"🎯 Predicción de score: {prediction[0][0]:.2f}\")\n"
      ],
      "metadata": {
        "id": "HHN9HeAPcqo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"Máximo y mínimo de y:\", np.max(y), np.min(y))\n"
      ],
      "metadata": {
        "id": "dVat-Kdnc3Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(...)  # ← si lo guardaste\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Evolución de pérdida\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ckUKHKNMc7vy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}